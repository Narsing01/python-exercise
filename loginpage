
module "vpc" {
  source        = "../../modules/vpc"
  vpc_name      = var.vpc_name
  gcp_region    = var.gcp_region
  ip_cidr_range = var.ip_cidr_range
  subnet_name   = var.subent_name
  project_id    = var.project_id

  depends_on = [google_project_service.gcp_services]
}



module "gke" {
  source                = "../../modules/gke"
  gke_cluster_name      = var.gke_cluster_name
  location              = var.gcp_region
  vpc_name              = var.vpc_name
  subnet_name           = var.subent_name
  channel               = var.channel
  project_id            = var.project_id
  max_pods_per_node     = var.max_pods_per_node
  authorized_networks   = var.authorized_networks
  ip_cidr_range         = var.ip_cidr_range
  service_account_roles = var.service_account_roles
  service_account       = var.service_account
  min_master_version    = var.min_master_version
  maintenance_window    = var.maintenance_window

  depends_on = [module.vpc]
  node_pools = var.node_pools
}


module "postgresql" {
  source              = "../../modules/postgresql"
  postgres_settings   = var.postgres_settings
  postgress_db_users  = var.postgress_db_users
  postgress_databases = var.postgress_databases
  vpc_name            = var.vpc_name
  service_account     = var.service_account

  depends_on = [module.gke]
}


module "gcs" {
  source      = "../../modules/gcs"
  project_id  = var.project_id
  gcp_region  = var.gcp_region
  gcs_buckets = var.gcs_buckets

  depends_on = [module.postgresql]
}


module "dataset" {
  source     = "../../modules/dataset"
  project_id = var.project_id
  bq_dataset = var.bq_dataset
  gcp_region = var.gcp_region

}


module "instances" {
  source      = "../../modules/instances"
  instance    = var.instance
  vpc_name    = var.vpc_name
  subent_name = var.subent_name
  gcp_region  = var.gcp_region

  pd         = var.pd
  project_id = var.project_id

  depends_on = [module.vpc]

  # prod-gitlab = var.prod-gitlab
}


////gkemain

# # Googke Kubernetes Engine

data "google_project" "project" {
  project_id = var.project_id
}


# locals {
#   # GKE clusters are regional if is_multi_zonal is true.
#   #location = var.is_multi_zonal == true ? var.region : var.zone

#   static_resource_labels = {
#     "cluster_name" = var.gke_cluster_name
#   }

#   variable_resource_labels = { for k, v in var.cluster_resource_labels : k => v if !contains(["asmv"], k) }
# }



resource "google_service_account" "gke-sa" {
  account_id   = var.service_account
  display_name = "Service Account"
}



# Add the required roles to the Workload Identity SA
resource "google_project_iam_member" "role" {
  for_each = var.service_account_roles
  provider = google-beta
  project  = var.project_id
  member   = "serviceAccount:${google_service_account.gke-sa.email}"
  role     = each.value

  depends_on = [google_service_account.gke-sa]

}



locals {
  clusters = {
    for cluster in var.gke_cluster_name : cluster.name => cluster
  }
}


locals {
  node_pools = {
    for node_pool in var.node_pools : node_pool.name => node_pool
  }
}



resource "google_container_cluster" "valor-dev" {
  for_each = local.clusters

  name               = each.value.name
  location           = each.value.location
  min_master_version = var.min_master_version


  deletion_protection       = false
  default_max_pods_per_node = var.max_pods_per_node

  ### Uncomment below block for filestore instance

  enable_shielded_nodes = true
  dynamic "maintenance_policy" {
    for_each = var.maintenance_window == null ? [] : tolist(var.maintenance_window)
    content {
      recurring_window {
        start_time = maintenance_policy.value.maintenance_start_time
        end_time   = maintenance_policy.value.maintenance_end_time
        recurrence = maintenance_policy.value.maintenance_recurrence
      }
    }
  }

  remove_default_node_pool = true
  network                  = var.vpc_name
  subnetwork               = var.subnet_name

  private_cluster_config {

    enable_private_nodes    = true
    enable_private_endpoint = false



    # master_ipv4_cidr_block = cidrsubnet(google_compute_address.vpc_network.cidr_range, 28 + count.index) 
    master_ipv4_cidr_block = var.ip_cidr_range.master[each.key]

    master_global_access_config {
      enabled = false
    }
  }


  master_authorized_networks_config {
    dynamic "cidr_blocks" {
      for_each = var.authorized_networks
      content {
        cidr_block   = cidr_blocks.value.cidr_block
        display_name = cidr_blocks.value.display_name
      }
    }
  }


  release_channel {
    channel = var.channel
  }

  #   # We can't create a cluster with no node pool defined, but we want to only use
  #   # separately managed node pools. So we create the smallest possible default
  #   # node pool and immediately delete it.

  initial_node_count = 1

  vertical_pod_autoscaling {
    enabled = true

  }
  cost_management_config {
    enabled = true
  }

  workload_identity_config {
    workload_pool = "${data.google_project.project.project_id}.svc.id.goog"
  }

  # Enable GKE Gateway
  gateway_api_config {
    channel = "CHANNEL_STANDARD"
  }

  ip_allocation_policy {
    cluster_secondary_range_name  = "pods"
    services_secondary_range_name = "services"
  }


  ## Place holder to enable Cloud_DNS for kube-dns

  dns_config {
    cluster_dns       = "CLOUD_DNS"
    cluster_dns_scope = "CLUSTER_SCOPE"
  }

  addons_config {
    horizontal_pod_autoscaling {
      disabled = false
    }
    http_load_balancing {
      disabled = false
    }
    dns_cache_config {
      enabled = true
    }

    # The status of the GCSFuse CSI driver addon, 
    # which allows the usage of a gcs bucket as volumes
    gcs_fuse_csi_driver_config {
      enabled = true
    }

    # istio_config {
    #   disabled = true
    # }

    ### Uncomment below block for filestore instance
    gcp_filestore_csi_driver_config {   //to access and manage Google Cloud Filestore instances.
      enabled = true
    }

    config_connector_config {
      enabled = true
    }

  }

  # The logging service that the cluster should write logs to
  # Legacy Stackdriver or Stackdriver Kubernetes Engine Logging
  logging_service = "logging.googleapis.com/kubernetes"

  # The monitoring service that the cluster should write logs to
  monitoring_service = "monitoring.googleapis.com/kubernetes"


  master_auth {
    client_certificate_config {
      issue_client_certificate = false  //client certificates won't be issued for the control plane 
    }
  }

  network_policy {
    provider = "CALICO"
    enabled  = true
  }


  networking_mode = "VPC_NATIVE"

  # resource_labels = merge(local.variable_resource_labels, local.static_resource_labels)

}


resource "google_container_node_pool" "pools" {
  for_each = local.node_pools
  name     = each.value.name
  cluster  = each.value.cluster
  location = each.value.location
  project  = var.project_id


  depends_on = [
    google_container_cluster.valor-dev
  ]


  initial_node_count = each.value.nodes_initial
  autoscaling {
    min_node_count = each.value.nodes_min
    max_node_count = each.value.nodes_max
  }

  upgrade_settings {
    max_unavailable = each.value.max_unavailable # The maximum number of nodes upgraded, hence unavailable during upgrade
    max_surge       = each.value.max_surge       # The maximum number of new temporary nodes provisioned to handle upgrades
  }

  management {
    auto_repair  = true
    auto_upgrade = true
  }

  max_pods_per_node = var.max_pods_per_node

  node_config {
    disk_size_gb = each.value.disk_size_gb
    disk_type    = each.value.disk_type
    image_type   = each.value.image_type


    preemptible  = false
    machine_type = each.value.machine_type

    gcfs_config {
      enabled = true
    }

    # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
    service_account = google_service_account.gke-sa.email
    shielded_instance_config {
      enable_secure_boot          = true
      enable_integrity_monitoring = true
    }

    dynamic "guest_accelerator" {
      for_each = each.value.guest_accelerator_count > 0 ? [1] : []
      content {
        count = each.value.guest_accelerator_count
        type  = each.value.guest_accelerator_type
        gpu_driver_installation_config {
          gpu_driver_version = "LATEST"
        }
        gpu_sharing_config {
          gpu_sharing_strategy       = each.value.gpu_sharing_strategy
          max_shared_clients_per_gpu = each.value.max_shared_clients_per_gpu
        }
      }
    }


    # Implied by Workload Identity
    workload_metadata_config {
      mode = "GKE_METADATA"
    }

    # Implied by workload identity.
    metadata = {
      "disable-legacy-endpoints" = "true"
    }

    oauth_scopes = [
      "https://www.googleapis.com/auth/cloud-platform"
    ]

    labels = {
      gke-purpose = each.value.name
      role        = each.value.name
    }
    tags = []
  }
}




//variale


# variable "gke_cluster_name" {
#   description = "The name of the VPC to create"
#   type        = string
# }


variable "location" {
  description = "The default region for GKE cluster"
  type        = string
}


variable "vpc_name" {
  description = "The name of the VPC to create"
  type        = string
}


variable "subnet_name" {
  description = "The name of the VPC to create"
  type        = string
}



variable "maintenance_window" {
  description = "Specify a cluster maintenance window"
  type = list(object({
    maintenance_start_time = string
    maintenance_end_time   = string
    maintenance_recurrence = string
  }))
}

variable "ip_cidr_range" {
  type = object({
    nodes    = string
    master   = map(string)
    pods     = string
    services = string
  })
}


variable "authorized_networks" {
  description = "List of authorized networks that are allowed to talk to the GKE Master"
  type = list(object({
    cidr_block   = string
    display_name = string
  }))
}


variable "gke_cluster_name" {
  description = "List of clusters where we define configuration of each cluster"
  type = list(object({
    name     = string
    location = string
  }))
}


variable "channel" {
  description = "GKE Release channel"
  type        = string
}


# variable "cluster_resource_labels" {
#   type        = map(string)
#   description = "List of labels to be added"
# }

variable "min_master_version" {
  type = string
}

variable "service_account" {
  description = "Service account name of GKE"
  type        = string
}


variable "service_account_roles" {
  description = "List of IAM roles required for GKE nodes"
  type        = set(string)
}


variable "max_pods_per_node" {
  description = "Max pods per node"
  type        = number
}


variable "project_id" {
  type        = string
  description = "gcp project id"
}


variable "node_pools" {
  description = "List of node pools where we define a min and a max number of nodes, and if is gVisor enabled"
  #default     = []
  type = list(object({
    name            = string
    cluster         = string
    nodes_initial   = number
    nodes_min       = number
    nodes_max       = number
    machine_type    = string
    location        = string
    image_type      = string
    max_surge       = number
    max_unavailable = number
    disk_type       = string
    auto_upgrade    = string
    disk_size_gb    = number

    sandbox = bool

    # Determines the number and type of accelerators cards (e.g. GPUs) attached
    # to each node in the pool. If the node pool does not require accelerators,
    # set guest_accelerator_count = 0 and guest_accelerator_type = "".
    guest_accelerator_count    = number
    guest_accelerator_type     = string
    gpu_sharing_strategy       = string
    max_shared_clients_per_gpu = number
  }))
}



//vpc


resource "google_compute_network" "private_network" {
  name                    = var.vpc_name
  routing_mode            = "GLOBAL"
  auto_create_subnetworks = false


}


resource "google_compute_subnetwork" "private_subnetwork" {
  name          = var.subnet_name
  description   = "Subnet for GKE Pods and Services"
  ip_cidr_range = var.ip_cidr_range.nodes
  region        = var.gcp_region
  network       = google_compute_network.private_network.id

  private_ip_google_access = true


  secondary_ip_range {
    range_name    = "pods"
    ip_cidr_range = var.ip_cidr_range.pods
  }

  secondary_ip_range {
    range_name    = "services"
    ip_cidr_range = var.ip_cidr_range.services
  }

  # dynamic "log_config" {
  #   for_each = var.vpc_flow_log_enable == true ? [1] : []
  #   content {
  #     flow_sampling = 1.0
  #     metadata      = "INCLUDE_ALL_METADATA"
  #   }
  # }

  depends_on = [google_compute_network.private_network]
}


resource "google_compute_global_address" "private_ip_block" {
  name         = "dspl-private-ip-block"
  description  = "A block of private IP addresses that are accessible only from within the VPC."
  purpose      = "VPC_PEERING"
  address_type = "INTERNAL"
  ip_version   = "IPV4"
  # We don't specify a address range because Google will automatically assign one for us.
  prefix_length = 20 #4k IPs

  network = google_compute_network.private_network.self_link

  depends_on = [google_compute_subnetwork.private_subnetwork]
}



resource "google_service_networking_connection" "private_vpc_connection" {
  network                 = google_compute_network.private_network.self_link
  service                 = "servicenetworking.googleapis.com"
  reserved_peering_ranges = [google_compute_global_address.private_ip_block.name]
  depends_on              = [google_compute_global_address.private_ip_block]
  provider                = google-beta
}



resource "google_compute_router" "router" {
  project = var.project_id
  name    = "vpc-router-${var.vpc_name}"
  network = google_compute_network.private_network.id
  region  = google_compute_subnetwork.private_subnetwork.region

  bgp {
    asn = 64514
  }

  depends_on = [google_service_networking_connection.private_vpc_connection]
}



resource "google_compute_router_nat" "nat" {
  name                               = "vpc-router-nat-${var.vpc_name}"
  router                             = google_compute_router.router.name
  region                             = google_compute_router.router.region
  nat_ip_allocate_option             = "AUTO_ONLY"
  source_subnetwork_ip_ranges_to_nat = "ALL_SUBNETWORKS_ALL_IP_RANGES"


  log_config {
    enable = true
    filter = "ERRORS_ONLY"
  }

  depends_on = [google_compute_router.router]
}



//var

variable "vpc_name" {
  description = "The name of the VPC to create"
  type        = string
}

variable "subnet_name" {
  description = "The name of the VPC to create"
  type        = string
}

variable "project_id" {
  type        = string
  description = "gcp project id"
}


variable "gcp_region" {
  type        = string
  description = "location for resources"
}

# variable "ip_cidr_range" {
#   description = "Cluster CIDR IPs for Nodes, Pods, and Services. Each CIDR is represeted as, e.g., 10.10.0.0/20"
#   type = object({
#     nodes    = string
#     pods     = string
#     services = string
#     master   = string
#   })
# }

variable "ip_cidr_range" {
  type = object({
    nodes    = string
    master   = object({})
    pods     = string
    services = string
  })
}
